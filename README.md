
# TransLib
TransLib, an open-source kernel library based on transprecision computing principles, provides knobs to exploit different FP data types (i.e., float, float16, and bfloat16), also considering the trade-off between homogeneous and mixed-precision solutions. 

We demonstrate the capabilities of the proposed library on PULP, a 32-bit microcontroller (MCU) coupled with a parallel, programmable accelerator. We performed a comparative analysis of seven standard kernels used in IoT end-node processing to evaluate our proposed method.

# Reference
If you use the TransLib, you can cite our paper ([TransLib](https://ieeexplore.ieee.org/abstract/document/10136916)): 
~~~~~shell
@INPROCEEDINGS{10136916,
  author={Mirsalari, Seyed Ahmad and Tagliavini, Giuseppe and Rossi, Davide and Benini, Luca},
  booktitle={2023 Design, Automation & Test in Europe Conference & Exhibition (DATE)}, 
  title={TransLib: A Library to Explore Transprecision Floating-Point Arithmetic on Multi-Core IoT End-Nodes}, 
  year={2023},
  volume={},
  number={},
  pages={1-2},
  doi={10.23919/DATE56975.2023.10136916}}
~~~~~
## Get Started
Each kernel design includes a Python model and a C program. The Python model generates the input dataset, computes the kernel output as a golden reference, and assesses the accuracy using a customizable error metric. Each folder contains a specific test with the golden model generator and a brief description of how to run the test.  
### Prerequisites 
#### Python
These golden models are built on top of PyTorch data types. The following packages need to be installed:
~~~~~shell
pip install pandas torch matplotlib pywavelets scipy
~~~~~
#### PULP-SDK
These tests requires the [PULP-SDK](https://github.com/pulp-platform/pulp-sdk). Once you cloned the PULP-SDK repository and you have the [RISC-V GNU Compiler Toolchain](https://github.com/pulp-platform/pulp-riscv-gnu-toolchain) installed, you need to compile [GVSOC](https://github.com/pulp-platform/pulp-sdk#gvsoc). **Please refer to the links to correctly setup your working environment.**

Here is my suggestion:

1-  First install and compile the [RISC-V GNU Compiler Toolchain](https://github.com/pulp-platform/pulp-riscv-gnu-toolchain#risc-v-gnu-compiler-toolchain).

Follow the next steps in the [RISC-V GNU Compiler Toolchain](https://github.com/pulp-platform/pulp-riscv-gnu-toolchain#risc-v-gnu-compiler-toolchain) repository.

- [Getting the sources](https://github.com/pulp-platform/pulp-riscv-gnu-toolchain#getting-the-sources)
- [Prerequisites](https://github.com/pulp-platform/pulp-riscv-gnu-toolchain#prerequisites)
- [Installation (Pulp)](https://github.com/pulp-platform/pulp-riscv-gnu-toolchain#installation-pulp)

2- Install and compile [PULP-SDK](https://github.com/pulp-platform/pulp-sdk#pulp-sdk).

Please follow the next setups in the [PULP-SDK](https://github.com/pulp-platform/pulp-sdk#pulp-sdk) repository
- [Getting started](https://github.com/pulp-platform/pulp-sdk#getting-started)
- [GVSoC](https://github.com/pulp-platform/pulp-sdk#gvsoc)

3- Finally, test the installation according to [Test execution](https://github.com/pulp-platform/pulp-sdk#test-execution)


**Don't forget to source the file corresponding to the desired configuration when you want to use the TransLib again** :

~~~~~shell
cd pulp-sdk
source configs/pulp-open.sh
~~~~~
## Repository Organization
Each folder contains a specific test with the golden model generator and a brief description of how to run the test.  

Since some kernels don't support mixed-precision in the current version, we have divided the kernels into [fixed-precision test ](./fixed_precision/) and [mixed-precision test](./mixed_precision/).
These are the developed tests:

- [Matrix Multiplication test](./mixed_precision/matmul/) for FP32, FP16 and FP16ALT with also vectorial format for half-precision floating-point
- [Convolution test](./mixed_precision/convolutioncl/) for FP32, FP16 and FP16ALT with also vectorial format for half-precision floating-point
- [DWT test](./fixed_precision/dwt) for FP32, FP16 and FP16ALT with also vectorial format for half-precision floating-point
- [FFT test](./fixed_precision/fft-memsave) for FP32, FP16 and FP16ALT with also vectorial format for half-precision floating-point
- [FIR filter test](./mixed_precision/fir) for FP32, FP16 and FP16ALT with also vectorial format for half-precision floating-point
- [K-means algorithm test](./fixed_precision/kmeans) for FP32, FP16 and FP16ALT with also vectorial format for half-precision floating-point
- [SVM classification test](./mixed_precision/SVM/) for FP32, FP16 and FP16ALT with also vectorial format for half-precision floating-point


## Roadmap

- Expand the library by adding additional kernels 

- Extend the support to additional FP data types (e.g., different flavors of 8-bit FP types) 

## License 
 TransLib is released under Apache 2.0, see the [LICENSE](./LICENSE.md) file in the root of this repository for details.

## Reference Paper
This library is based on the research outlined in the following paper:

- Mirsalari, S.A., Tagliavini, G., Rossi, D., and Benini, L., "TransLib: A Library to Explore Transprecision Floating-Point Arithmetic on Multi-Core IoT End-Nodes", 2023 Design, Automation & Test in Europe Conference & Exhibition (DATE), 2023, [Link to the paper](https://ieeexplore.ieee.org/abstract/document/10136916)

If you find this library useful in your research, please consider citing the paper:

```bibtex
@INPROCEEDINGS{10136916,
  author={Mirsalari, Seyed Ahmad and Tagliavini, Giuseppe and Rossi, Davide and Benini, Luca},
  booktitle={2023 Design, Automation & Test in Europe Conference & Exhibition (DATE)},
  title={TransLib: A Library to Explore Transprecision Floating-Point Arithmetic on Multi-Core IoT End-Nodes},
  year={2023},
  volume={},
  number={},
  pages={1-2},
  doi={10.23919/DATE56975.2023.10136916}}

## Acknowledgements
This work was supported by the [APROPOS](https://projects.tuni.fi/apropos/) project (g.a. no. 956090), founded by the European Unionâ€™s Horizon 2020 research and innovation program. 


## Contributors
- [Seyed Ahmad Mirsalari](https://github.com/ahmad-mirsalari), University of Bologna,[E-mail](mailto:seyedahmad.mirsalar2@unibo.it)
- [Giuseppe Tagliavini](https://github.com/gtagliavini), University of Bologna,[E-mail](mailto:giuseppe.tagliavini@unibo.it)


## ðŸš€ Contact Me
- [Email](mailto:seyedahmad.mirsalar2@unibo.it)
- [LinkedIn](https://www.linkedin.com/in/ahmad-mirsalari/)
- [Twitter](https://twitter.com/ahmad_mirsalari)
- [APROPOS](https://projects.tuni.fi/apropos/news/pr_esr_3/)
